[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelos Lineares I - Seminário",
    "section": "",
    "text": "Introdução\nEste material faz parte da disciplina LCE5861 - Modelos Lineares I, ministrada pelo prof. Dr. César Gonçalves de Lima na ESALQ/USP, como parte do Programa de Pós-Graduação em Estatística e Experimentação Agronômica.\nSerão apresentados exercícios e exemplos de aulas resolvidos com o software SAS, os quais foram convertidos para a linguagem de programação R. Parte desses exercícios e exemplos são oriundos de Rencher e Schaalje (2008)1.\nPara acessar o script em R, clique aqui. Para acessar os scripts em SAS, clique aqui."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Modelos Lineares I - Seminário",
    "section": "",
    "text": "Rencher, A. C.; Schaalje, G. B. (2008). Linear models in Statistics, 2ª ed. New York: Wiley.↩︎"
  },
  {
    "objectID": "exemplo1.html#vetores-e-matriz",
    "href": "exemplo1.html#vetores-e-matriz",
    "title": "\n1  Exemplo\n",
    "section": "\n1.1 Vetores e Matriz",
    "text": "1.1 Vetores e Matriz\n\n\nR\nSAS\n\n\n\nPara criar vetores no R, definimos um nome para cada vetor (y1, y2, y3 e y4), em seguida, utilizamos o operador &lt;- e a função c() para atribuir valores a cada um dos objetos (vetores). Dentro de c(), declaramos seus valores, separados por vírgula.\n\ny1 &lt;- c(72,60,56,41,32,30,39,42,37,33,32,63,54,47,91,56,79,81,78,46,39,32,60,35,39,50,43,48)\n\ny2 &lt;- c(66,53,57,29,32,35,39,43,40,29,30,45,46,51,79,68,65,80,55,38,35,30,50,37,36,34,37,54)\n\ny3 &lt;- c(76,66,64,36,35,34,31,31,31,27,34,74,60,52,100,47,70,68,67,37,34,30,67,48,39,37,39,57)\n\ny4 &lt;- c(77,63,58,38,36,26,27,25,25,36,28,63,52,43,75,50,61,58,60,38,37,32,54,39,31,40,50,43)\n\nCom a função cbind() juntamos os vetores y1, y2, y3 e y4, salvando-os em um objeto chamado Y. Utilizando a função colnames(), alteramos os nomes dos vetores (\"North\", \"East\", \"South\", \"West\").\n\nY &lt;- cbind(y1, y2, y3, y4)\ncolnames(Y) &lt;- c(\"North\", \"East\", \"South\", \"West\")\nY\n\n      North East South West\n [1,]    72   66    76   77\n [2,]    60   53    66   63\n [3,]    56   57    64   58\n [4,]    41   29    36   38\n [5,]    32   32    35   36\n [6,]    30   35    34   26\n [7,]    39   39    31   27\n [8,]    42   43    31   25\n [9,]    37   40    31   25\n[10,]    33   29    27   36\n[11,]    32   30    34   28\n[12,]    63   45    74   63\n[13,]    54   46    60   52\n[14,]    47   51    52   43\n[15,]    91   79   100   75\n[16,]    56   68    47   50\n[17,]    79   65    70   61\n[18,]    81   80    68   58\n[19,]    78   55    67   60\n[20,]    46   38    37   38\n[21,]    39   35    34   37\n[22,]    32   30    30   32\n[23,]    60   50    67   54\n[24,]    35   37    48   39\n[25,]    39   36    39   31\n[26,]    50   34    37   40\n[27,]    43   37    39   50\n[28,]    48   54    57   43\n\n\nCom a função class(), constatamos que o objeto Y é uma matriz (matrix).\n\nclass(Y)\n\n[1] \"matrix\" \"array\" \n\n\n\n\n\nproc iml;\n\ny1 = {72,60,56,41,32,30,39,42,37,33,32,63,54,47, 91,56,79,81,78,46, 39,32,60,35,39,50,43,48};\n\ny2 = {66,53,57,29,32,35,39,43,40,29,30,45,46,51, 79,68,65,80,55,38, 35,30,50,37,36,34,37,54};\n\ny3 = {76,66,64,36,35,34,31,31,31,27,34,74,60,52,100,47,70,68,67,37, 34,30,67,48,39,37,39,57};\n\ny4 = {77,63,58,38,36,26,27,25,25,36,28,63,52,43, 75,50,61,58,60,38, 37,32,54,39,31,40,50,43};\n\n\nY = y1||y2||y3||y4;\ncreate Cork var {North East South West};\nappend from Y;\nClose Cork;"
  },
  {
    "objectID": "exemplo1.html#matriz-de-variâncias-e-covariâncias",
    "href": "exemplo1.html#matriz-de-variâncias-e-covariâncias",
    "title": "\n1  Exemplo\n",
    "section": "\n1.2 Matriz de Variâncias e Covariâncias",
    "text": "1.2 Matriz de Variâncias e Covariâncias\nPara obtermos a matriz de variâncias e covariâncias, precisamos dos seguintes escalares, vetores e matrizes:\n\nn: número de observações \\(n\\);\nIn: matriz identidade \\(\\mathbf{I}\\);\njn: vetor coluna de 1’s \\(\\mathbf{j}\\);\nJnn: matriz de 1’s \\(\\mathbf{J}\\).\n\n\n\nR\nSAS\n\n\n\nAs funções nrow() e ncol() nos retornam o número de linhas e colunas de um objeto, respectivamente.\n\nn &lt;- nrow(Y)\np &lt;- ncol(Y)\n\nn; p\n\n[1] 28\n\n\n[1] 4\n\n\nNo caso da matriz Y, ela apresenta dimensão \\(28 \\times 4\\).\nA função diag() cria uma matriz identidade. Basta inserir dentro da função a dimensão da matriz.\n\nIn &lt;- diag(n)\nIn\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n [1,]    1    0    0    0    0    0    0    0    0     0     0     0     0\n [2,]    0    1    0    0    0    0    0    0    0     0     0     0     0\n [3,]    0    0    1    0    0    0    0    0    0     0     0     0     0\n [4,]    0    0    0    1    0    0    0    0    0     0     0     0     0\n [5,]    0    0    0    0    1    0    0    0    0     0     0     0     0\n [6,]    0    0    0    0    0    1    0    0    0     0     0     0     0\n [7,]    0    0    0    0    0    0    1    0    0     0     0     0     0\n [8,]    0    0    0    0    0    0    0    1    0     0     0     0     0\n [9,]    0    0    0    0    0    0    0    0    1     0     0     0     0\n[10,]    0    0    0    0    0    0    0    0    0     1     0     0     0\n[11,]    0    0    0    0    0    0    0    0    0     0     1     0     0\n[12,]    0    0    0    0    0    0    0    0    0     0     0     1     0\n[13,]    0    0    0    0    0    0    0    0    0     0     0     0     1\n[14,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[15,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[16,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[17,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[18,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[19,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[20,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[21,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[22,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[23,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[24,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[25,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[26,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[27,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[28,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\n [1,]     0     0     0     0     0     0     0     0     0     0     0     0\n [2,]     0     0     0     0     0     0     0     0     0     0     0     0\n [3,]     0     0     0     0     0     0     0     0     0     0     0     0\n [4,]     0     0     0     0     0     0     0     0     0     0     0     0\n [5,]     0     0     0     0     0     0     0     0     0     0     0     0\n [6,]     0     0     0     0     0     0     0     0     0     0     0     0\n [7,]     0     0     0     0     0     0     0     0     0     0     0     0\n [8,]     0     0     0     0     0     0     0     0     0     0     0     0\n [9,]     0     0     0     0     0     0     0     0     0     0     0     0\n[10,]     0     0     0     0     0     0     0     0     0     0     0     0\n[11,]     0     0     0     0     0     0     0     0     0     0     0     0\n[12,]     0     0     0     0     0     0     0     0     0     0     0     0\n[13,]     0     0     0     0     0     0     0     0     0     0     0     0\n[14,]     1     0     0     0     0     0     0     0     0     0     0     0\n[15,]     0     1     0     0     0     0     0     0     0     0     0     0\n[16,]     0     0     1     0     0     0     0     0     0     0     0     0\n[17,]     0     0     0     1     0     0     0     0     0     0     0     0\n[18,]     0     0     0     0     1     0     0     0     0     0     0     0\n[19,]     0     0     0     0     0     1     0     0     0     0     0     0\n[20,]     0     0     0     0     0     0     1     0     0     0     0     0\n[21,]     0     0     0     0     0     0     0     1     0     0     0     0\n[22,]     0     0     0     0     0     0     0     0     1     0     0     0\n[23,]     0     0     0     0     0     0     0     0     0     1     0     0\n[24,]     0     0     0     0     0     0     0     0     0     0     1     0\n[25,]     0     0     0     0     0     0     0     0     0     0     0     1\n[26,]     0     0     0     0     0     0     0     0     0     0     0     0\n[27,]     0     0     0     0     0     0     0     0     0     0     0     0\n[28,]     0     0     0     0     0     0     0     0     0     0     0     0\n      [,26] [,27] [,28]\n [1,]     0     0     0\n [2,]     0     0     0\n [3,]     0     0     0\n [4,]     0     0     0\n [5,]     0     0     0\n [6,]     0     0     0\n [7,]     0     0     0\n [8,]     0     0     0\n [9,]     0     0     0\n[10,]     0     0     0\n[11,]     0     0     0\n[12,]     0     0     0\n[13,]     0     0     0\n[14,]     0     0     0\n[15,]     0     0     0\n[16,]     0     0     0\n[17,]     0     0     0\n[18,]     0     0     0\n[19,]     0     0     0\n[20,]     0     0     0\n[21,]     0     0     0\n[22,]     0     0     0\n[23,]     0     0     0\n[24,]     0     0     0\n[25,]     0     0     0\n[26,]     1     0     0\n[27,]     0     1     0\n[28,]     0     0     1\n\n\n\\[\n\\mathbf{I}_{(n)} =\n  \\begin{bmatrix}\n   1 & 0 & 0 & \\dots & 0 \\\\\n   0 & 1 & 0 & \\dots & 0 \\\\\n   0 & 0 & 1 &\\dots & 0 \\\\\n   \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n   0 & 0 & 0 & \\dots & 1\n   \\end{bmatrix}\n\\]\nCom a função matrix(), podemos criar qualquer tipo de matriz, vetor ou escalar. Para isso, utilizamos três argumentos dentro da função:\n\ndata =: os elementos que compõem a matriz;\nnrow =: número de linhas da matriz;\nncol =: número de colunas da matriz.\n\n\njn &lt;- matrix(data = 1, nrow = n, ncol = 1)\njn\n\n      [,1]\n [1,]    1\n [2,]    1\n [3,]    1\n [4,]    1\n [5,]    1\n [6,]    1\n [7,]    1\n [8,]    1\n [9,]    1\n[10,]    1\n[11,]    1\n[12,]    1\n[13,]    1\n[14,]    1\n[15,]    1\n[16,]    1\n[17,]    1\n[18,]    1\n[19,]    1\n[20,]    1\n[21,]    1\n[22,]    1\n[23,]    1\n[24,]    1\n[25,]    1\n[26,]    1\n[27,]    1\n[28,]    1\n\nJnn &lt;- matrix(data = 1, nrow = n, ncol = n)\nJnn\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n [1,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [2,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [3,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [4,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [5,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [6,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [7,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [8,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [9,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[10,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[11,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[12,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[13,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[14,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[15,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[16,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[17,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[18,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[19,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[20,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[21,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[22,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[23,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[24,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[25,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[26,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[27,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[28,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\n [1,]     1     1     1     1     1     1     1     1     1     1     1     1\n [2,]     1     1     1     1     1     1     1     1     1     1     1     1\n [3,]     1     1     1     1     1     1     1     1     1     1     1     1\n [4,]     1     1     1     1     1     1     1     1     1     1     1     1\n [5,]     1     1     1     1     1     1     1     1     1     1     1     1\n [6,]     1     1     1     1     1     1     1     1     1     1     1     1\n [7,]     1     1     1     1     1     1     1     1     1     1     1     1\n [8,]     1     1     1     1     1     1     1     1     1     1     1     1\n [9,]     1     1     1     1     1     1     1     1     1     1     1     1\n[10,]     1     1     1     1     1     1     1     1     1     1     1     1\n[11,]     1     1     1     1     1     1     1     1     1     1     1     1\n[12,]     1     1     1     1     1     1     1     1     1     1     1     1\n[13,]     1     1     1     1     1     1     1     1     1     1     1     1\n[14,]     1     1     1     1     1     1     1     1     1     1     1     1\n[15,]     1     1     1     1     1     1     1     1     1     1     1     1\n[16,]     1     1     1     1     1     1     1     1     1     1     1     1\n[17,]     1     1     1     1     1     1     1     1     1     1     1     1\n[18,]     1     1     1     1     1     1     1     1     1     1     1     1\n[19,]     1     1     1     1     1     1     1     1     1     1     1     1\n[20,]     1     1     1     1     1     1     1     1     1     1     1     1\n[21,]     1     1     1     1     1     1     1     1     1     1     1     1\n[22,]     1     1     1     1     1     1     1     1     1     1     1     1\n[23,]     1     1     1     1     1     1     1     1     1     1     1     1\n[24,]     1     1     1     1     1     1     1     1     1     1     1     1\n[25,]     1     1     1     1     1     1     1     1     1     1     1     1\n[26,]     1     1     1     1     1     1     1     1     1     1     1     1\n[27,]     1     1     1     1     1     1     1     1     1     1     1     1\n[28,]     1     1     1     1     1     1     1     1     1     1     1     1\n      [,26] [,27] [,28]\n [1,]     1     1     1\n [2,]     1     1     1\n [3,]     1     1     1\n [4,]     1     1     1\n [5,]     1     1     1\n [6,]     1     1     1\n [7,]     1     1     1\n [8,]     1     1     1\n [9,]     1     1     1\n[10,]     1     1     1\n[11,]     1     1     1\n[12,]     1     1     1\n[13,]     1     1     1\n[14,]     1     1     1\n[15,]     1     1     1\n[16,]     1     1     1\n[17,]     1     1     1\n[18,]     1     1     1\n[19,]     1     1     1\n[20,]     1     1     1\n[21,]     1     1     1\n[22,]     1     1     1\n[23,]     1     1     1\n[24,]     1     1     1\n[25,]     1     1     1\n[26,]     1     1     1\n[27,]     1     1     1\n[28,]     1     1     1\n\n\nNos casos anteriores, criamos o vetor coluna de 1’s jn de dimensão \\(28 \\times 1\\) e a matriz de 1’s Jnn de dimensão \\(28 \\times 28\\).\n\\[\nj_n = \\mathbf{j}_{(28 \\times 1)} = [1,1,...,1]'\n\\]\n\\[\nJnn = \\mathbf{J}_{(28 \\times 28)} =\n  \\begin{bmatrix}\n   1 & 1 & 1 & \\dots & 1 \\\\\n   1 & 1 & 1 & \\dots & 1 \\\\\n   1 & 1 & 1 &\\dots & 1 \\\\\n   \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n   1 & 1 & 1 & \\dots & 1\n   \\end{bmatrix}\n\\]\nAlém disso, note que a matriz \\(\\mathbf{J}\\) (Jnn) pode ser obtida por \\(\\mathbf{J} = \\mathbf{j} \\space \\mathbf{j}'\\), ou seja, a multiplicação do vetor coluna \\(\\mathbf{j}\\) (jn) pela sua transposta.\nNo R, utilizamos a função t() para realizar a transposição de uma matriz ou vetor.\n\nJnn &lt;- jn %*% t(jn)\nJnn\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n [1,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [2,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [3,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [4,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [5,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [6,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [7,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [8,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [9,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[10,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[11,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[12,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[13,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[14,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[15,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[16,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[17,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[18,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[19,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[20,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[21,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[22,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[23,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[24,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[25,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[26,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[27,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[28,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\n [1,]     1     1     1     1     1     1     1     1     1     1     1     1\n [2,]     1     1     1     1     1     1     1     1     1     1     1     1\n [3,]     1     1     1     1     1     1     1     1     1     1     1     1\n [4,]     1     1     1     1     1     1     1     1     1     1     1     1\n [5,]     1     1     1     1     1     1     1     1     1     1     1     1\n [6,]     1     1     1     1     1     1     1     1     1     1     1     1\n [7,]     1     1     1     1     1     1     1     1     1     1     1     1\n [8,]     1     1     1     1     1     1     1     1     1     1     1     1\n [9,]     1     1     1     1     1     1     1     1     1     1     1     1\n[10,]     1     1     1     1     1     1     1     1     1     1     1     1\n[11,]     1     1     1     1     1     1     1     1     1     1     1     1\n[12,]     1     1     1     1     1     1     1     1     1     1     1     1\n[13,]     1     1     1     1     1     1     1     1     1     1     1     1\n[14,]     1     1     1     1     1     1     1     1     1     1     1     1\n[15,]     1     1     1     1     1     1     1     1     1     1     1     1\n[16,]     1     1     1     1     1     1     1     1     1     1     1     1\n[17,]     1     1     1     1     1     1     1     1     1     1     1     1\n[18,]     1     1     1     1     1     1     1     1     1     1     1     1\n[19,]     1     1     1     1     1     1     1     1     1     1     1     1\n[20,]     1     1     1     1     1     1     1     1     1     1     1     1\n[21,]     1     1     1     1     1     1     1     1     1     1     1     1\n[22,]     1     1     1     1     1     1     1     1     1     1     1     1\n[23,]     1     1     1     1     1     1     1     1     1     1     1     1\n[24,]     1     1     1     1     1     1     1     1     1     1     1     1\n[25,]     1     1     1     1     1     1     1     1     1     1     1     1\n[26,]     1     1     1     1     1     1     1     1     1     1     1     1\n[27,]     1     1     1     1     1     1     1     1     1     1     1     1\n[28,]     1     1     1     1     1     1     1     1     1     1     1     1\n      [,26] [,27] [,28]\n [1,]     1     1     1\n [2,]     1     1     1\n [3,]     1     1     1\n [4,]     1     1     1\n [5,]     1     1     1\n [6,]     1     1     1\n [7,]     1     1     1\n [8,]     1     1     1\n [9,]     1     1     1\n[10,]     1     1     1\n[11,]     1     1     1\n[12,]     1     1     1\n[13,]     1     1     1\n[14,]     1     1     1\n[15,]     1     1     1\n[16,]     1     1     1\n[17,]     1     1     1\n[18,]     1     1     1\n[19,]     1     1     1\n[20,]     1     1     1\n[21,]     1     1     1\n[22,]     1     1     1\n[23,]     1     1     1\n[24,]     1     1     1\n[25,]     1     1     1\n[26,]     1     1     1\n[27,]     1     1     1\n[28,]     1     1     1\n\n\n\\[\n\\mathbf{J} = \\mathbf{j} \\space \\mathbf{j}' =\n\\begin{bmatrix}\n1 \\\\ 1 \\\\ \\vdots \\\\1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 1 & \\dots & 1\n\\end{bmatrix}\n=\n  \\begin{bmatrix}\n   1 & 1 & \\dots & 1 \\\\\n   1 & 1 & \\dots & 1 \\\\\n   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n   1 & 1 & \\dots & 1\n   \\end{bmatrix}\n\\]\nA seguir, calcularemos a matriz de variâncias e covariâncias amostrais, dada pela equação:\n\\[\\mathbf{\\Sigma} = \\frac{1}{n-1} \\mathbf{Y}'(\\mathbf{I} - \\frac{1}{n}J) \\mathbf{Y}\\]\n\nSigma &lt;- (1 / (n - 1)) * t(Y) %*% (In - (1/n) * Jnn) %*% Y\nSigma\n\n         North     East    South     West\nNorth 290.4061 223.7526 288.4378 226.2712\nEast  223.7526 219.9299 229.0595 171.3743\nSouth 288.4378 229.0595 350.0040 259.5410\nWest  226.2712 171.3743 259.5410 226.0040\n\n\nA função t() realiza a transposição de uma matriz ou vetor. Já o operador %*% realiza a multiplicação entre duas matrizes ou vetores conformes.\nNo R, temos a função cov() que realiza o cálculo da matriz de variâncias e covariâncias. Para isso, basta declarar dentro da função a matriz desejada.\n\ncov(Y)\n\n         North     East    South     West\nNorth 290.4061 223.7526 288.4378 226.2712\nEast  223.7526 219.9299 229.0595 171.3743\nSouth 288.4378 229.0595 350.0040 259.5410\nWest  226.2712 171.3743 259.5410 226.0040\n\n\n\\[\n\\mathbf{\\Sigma} =\n  \\begin{bmatrix}\n   \\sigma^2_1 & \\sigma_{12} & \\sigma_{13} & \\dots & \\sigma_{1p} \\\\\n   \\sigma_{21} & \\sigma^2_2 & \\sigma_{23} & \\dots & \\sigma_{2p} \\\\\n   \\sigma_{31} & \\sigma_{32} & \\sigma^2_3 &\\dots & \\sigma_{p3} \\\\\n   \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n   \\sigma_{p1} & \\sigma_{p2} & \\sigma_{p3} & \\dots & \\sigma^2_p\n   \\end{bmatrix}\n\\]\n\n1.3 Matriz de Correlações\nPara calcular a matriz de correlação (\\(\\mathbf{\\rho}_{ij}\\)), utilizamos a seguinte expressão:\n\\[\\mathbf{\\rho}_{ij} = \\mathbf{D}_{\\sigma}^{-1} \\mathbf{\\Sigma}  \\mathbf{D}_{\\sigma}^{-1}\\]\nem que \\(\\mathbf{D}_{\\sigma}\\) é uma matriz diagonal com a raiz quadrada das variâncias, ou seja, a raiz quadrada da diagonal da matriz de variâncias e covariâncias (\\(\\mathbf{\\Sigma}\\)).\n\nD &lt;- sqrt(diag(Sigma))\nD\n\n   North     East    South     West \n17.04131 14.83003 18.70839 15.03343 \n\ncorr &lt;- solve(diag(D)) %*% Sigma %*% solve(diag(D))\ncorr\n\n          [,1]      [,2]      [,3]      [,4]\n[1,] 1.0000000 0.8853667 0.9047173 0.8832188\n[2,] 0.8853667 1.0000000 0.8256001 0.7686801\n[3,] 0.9047173 0.8256001 1.0000000 0.9228082\n[4,] 0.8832188 0.7686801 0.9228082 1.0000000\n\n\nA função sqrt() realiza a operação raiz quadrada. Já a solve(), calcula a inversa de uma matriz.\nNo R, temos a função cor() que realiza o cálculo da matriz de correlação. Novamente, basta declarar a matriz dentro da função.\n\ncor(Y)\n\n          North      East     South      West\nNorth 1.0000000 0.8853667 0.9047173 0.8832188\nEast  0.8853667 1.0000000 0.8256001 0.7686801\nSouth 0.9047173 0.8256001 1.0000000 0.9228082\nWest  0.8832188 0.7686801 0.9228082 1.0000000\n\n\n\\[\n\\mathbf{\\rho} =\n  \\begin{bmatrix}\n   1 & \\rho_{12} & \\rho_{13} & \\dots & \\rho_{1p} \\\\\n   \\rho_{21} & 1 & \\rho_{23} & \\dots & \\rho_{2p} \\\\\n   \\rho_{31} & \\rho_{32} & 1 &\\dots & \\rho_{p3} \\\\\n   \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n   \\rho_{p1} & \\rho_{p2} & \\rho_{p3} & \\dots & 1\n   \\end{bmatrix}\n\\]\nPor fim, a partir da matriz de correlação (\\(\\mathbf{\\rho}_{ij}\\)), podemos retornar para a matriz de variâncias e covariâncias (\\(\\mathbf{\\Sigma}\\)) a partir da seguinte equação:\n\\[\n\\mathbf{\\Sigma} = \\mathbf{D}_{\\sigma} \\mathbf{\\rho}_{ij} \\mathbf{D}_{\\sigma}\n\\]\n\nVerifica &lt;- diag(D) %*% corr %*% diag(D)\nVerifica\n\n         [,1]     [,2]     [,3]     [,4]\n[1,] 290.4061 223.7526 288.4378 226.2712\n[2,] 223.7526 219.9299 229.0595 171.3743\n[3,] 288.4378 229.0595 350.0040 259.5410\n[4,] 226.2712 171.3743 259.5410 226.0040\n\n\n\n\n\n\np = ncol(Y);\nn = nrow(Y);\nIn = I(n);\njn = j(n,1,1);\nJnn = J(n,n,1);\nSigma = (1/(n-1))*t(Y)*(In-(1/n)*Jnn)*Y;\nD = sqrt(diag(Sigma));\ncorr = inv(D)*Sigma*inv(D);\nVerifica = D*corr*D;\ntitle 'Matriz de variâncias e covariâncias amostrais utilizando proc iml';\nprint ,,Sigma[format=8.4],, 'Matriz de correlações:' ,, corr[format=8.5],, Verifica[format=8.4];"
  },
  {
    "objectID": "exemplo1.html#matriz-de-correlações",
    "href": "exemplo1.html#matriz-de-correlações",
    "title": "\n1  Exemplo\n",
    "section": "\n1.3 Matriz de Correlações",
    "text": "1.3 Matriz de Correlações\nPara calcular a matriz de correlação (\\(\\mathbf{\\rho}_{ij}\\)), utilizamos a seguinte expressão:\n\\[\\mathbf{\\rho}_{ij} = \\mathbf{D}_{\\sigma}^{-1} \\mathbf{\\Sigma}  \\mathbf{D}_{\\sigma}^{-1}\\]\nem que \\(\\mathbf{D}_{\\sigma}\\) é uma matriz diagonal com a raiz quadrada das variâncias, ou seja, a raiz quadrada da diagonal da matriz de variâncias e covariâncias (\\(\\mathbf{\\Sigma}\\)).\n\nD &lt;- sqrt(diag(Sigma))\nD\n\n   North     East    South     West \n17.04131 14.83003 18.70839 15.03343 \n\ncorr &lt;- solve(diag(D)) %*% Sigma %*% solve(diag(D))\ncorr\n\n          [,1]      [,2]      [,3]      [,4]\n[1,] 1.0000000 0.8853667 0.9047173 0.8832188\n[2,] 0.8853667 1.0000000 0.8256001 0.7686801\n[3,] 0.9047173 0.8256001 1.0000000 0.9228082\n[4,] 0.8832188 0.7686801 0.9228082 1.0000000\n\n\nA função sqrt() realiza a operação raiz quadrada. Já a solve(), calcula a inversa de uma matriz.\nNo R, temos a função cor() que realiza o cálculo da matriz de correlação. Novamente, basta declarar a matriz dentro da função.\n\ncor(Y)\n\n          North      East     South      West\nNorth 1.0000000 0.8853667 0.9047173 0.8832188\nEast  0.8853667 1.0000000 0.8256001 0.7686801\nSouth 0.9047173 0.8256001 1.0000000 0.9228082\nWest  0.8832188 0.7686801 0.9228082 1.0000000\n\n\n\\[\n\\mathbf{\\rho} =\n  \\begin{bmatrix}\n   1 & \\rho_{12} & \\rho_{13} & \\dots & \\rho_{1p} \\\\\n   \\rho_{21} & 1 & \\rho_{23} & \\dots & \\rho_{2p} \\\\\n   \\rho_{31} & \\rho_{32} & 1 &\\dots & \\rho_{p3} \\\\\n   \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n   \\rho_{p1} & \\rho_{p2} & \\rho_{p3} & \\dots & 1\n   \\end{bmatrix}\n\\]\nPor fim, a partir da matriz de correlação (\\(\\mathbf{\\rho}_{ij}\\)), podemos retornar para a matriz de variâncias e covariâncias (\\(\\mathbf{\\Sigma}\\)) a partir da seguinte equação:\n\\[\n\\mathbf{\\Sigma} = \\mathbf{D}_{\\sigma} \\mathbf{\\rho}_{ij} \\mathbf{D}_{\\sigma}\n\\]\n\nVerifica &lt;- diag(D) %*% corr %*% diag(D)\nVerifica\n\n         [,1]     [,2]     [,3]     [,4]\n[1,] 290.4061 223.7526 288.4378 226.2712\n[2,] 223.7526 219.9299 229.0595 171.3743\n[3,] 288.4378 229.0595 350.0040 259.5410\n[4,] 226.2712 171.3743 259.5410 226.0040"
  },
  {
    "objectID": "exemplo1.html#distância-de-mahalanobis-distância-padronizada",
    "href": "exemplo1.html#distância-de-mahalanobis-distância-padronizada",
    "title": "\n1  Exemplo\n",
    "section": "\n1.4 Distância de Mahalanobis (Distância padronizada)",
    "text": "1.4 Distância de Mahalanobis (Distância padronizada)\n\n\nR\nSAS\n\n\n\nPrimeiramente, calcularemos o vetor de médias (\\(\\mathbf{\\mu}\\)) da matriz \\(\\mathbf{Y}\\).\n\\[\\mathbf{\\mu} = \\frac{1}n \\mathbf{j}' \\mathbf{Y}\\]\n\nmi &lt;- (1/n) * t(jn) %*% Y\nmi\n\n        North     East    South     West\n[1,] 50.53571 46.17857 49.67857 45.17857\n\n\nCom o vetor de médias (\\(\\mathbf{\\mu}\\)), calcularemos a distância de Mahalanobis (\\(DM\\)), dada pela seguinte expressão:\n\\[\nDM = (\\mathbf{y} - \\mathbf{\\mu})' \\mathbf{\\Sigma} (\\mathbf{y} - \\mathbf{\\mu})\n\\]\n\nDM2 &lt;- rep(0, n)\nfor (i in 1:n) {\n  yi &lt;- Y[i,]\n  DM &lt;- as.numeric((yi - mi) %*% solve(Sigma) %*% t(yi - mi))\n  DM2[i] &lt;- DM\n}\nDM2\n\n [1]  7.619457  2.509622  2.714316  2.521244  1.744186  3.069220  2.212975\n [8]  4.114008  2.800802  3.315503  2.099698  5.891095  1.062421  1.691059\n[15]  8.996903 10.409160  4.075630  8.576964  7.124169  1.434898  1.086315\n[22]  1.372791  2.110873  3.913168  1.647245  4.667263  5.412107  3.806908\n\n\nNo R, podemos utilizar a função mahalanobis() para calcular a distância de Mahalanobis. Como argumentos, temos:\n\nx =: matriz utilizada para o cálculo;\ncenter =: o vetor de médias (\\(\\mu\\));\ncov =: a matriz de variâncias e covariâncias (\\(\\Sigma\\)).\n\n\nmahalanobis(x = Y, center = mi, cov = Sigma)\n\n [1]  7.619457  2.509622  2.714316  2.521244  1.744186  3.069220  2.212975\n [8]  4.114008  2.800802  3.315503  2.099698  5.891095  1.062421  1.691059\n[15]  8.996903 10.409160  4.075630  8.576964  7.124169  1.434898  1.086315\n[22]  1.372791  2.110873  3.913168  1.647245  4.667263  5.412107  3.806908\n\n\nOrdenando os valores do vetor da distância de Mahalanobis, temos:\n\nrank &lt;- rank(DM2)\ndata.frame(Y, DM2, rank)\n\n   North East South West       DM2 rank\n1     72   66    76   77  7.619457   25\n2     60   53    66   63  2.509622   11\n3     56   57    64   58  2.714316   13\n4     41   29    36   38  2.521244   12\n5     32   32    35   36  1.744186    7\n6     30   35    34   26  3.069220   15\n7     39   39    31   27  2.212975   10\n8     42   43    31   25  4.114008   20\n9     37   40    31   25  2.800802   14\n10    33   29    27   36  3.315503   16\n11    32   30    34   28  2.099698    8\n12    63   45    74   63  5.891095   23\n13    54   46    60   52  1.062421    1\n14    47   51    52   43  1.691059    6\n15    91   79   100   75  8.996903   27\n16    56   68    47   50 10.409160   28\n17    79   65    70   61  4.075630   19\n18    81   80    68   58  8.576964   26\n19    78   55    67   60  7.124169   24\n20    46   38    37   38  1.434898    4\n21    39   35    34   37  1.086315    2\n22    32   30    30   32  1.372791    3\n23    60   50    67   54  2.110873    9\n24    35   37    48   39  3.913168   18\n25    39   36    39   31  1.647245    5\n26    50   34    37   40  4.667263   21\n27    43   37    39   50  5.412107   22\n28    48   54    57   43  3.806908   17\n\n\n\n\n\nmi = (1/n)*t(jn)*y;\nprint 'Vetor de médias:' mi[format=5.2],,;\n\n\nDM2 = j(n,1,0);\ni=1;\ndo while (i&lt;=n);\nyi= Y[i,];\nDM = (yi-mi)*inv(Sigma)*t(yi-mi);\nDM2[i] = DM;\ni=i+1;\nend;\n\nrank = rank(DM2);\nprint\n\n\n'-----------------------------------------------------------------',\n'Distância de Mahalanobis de cada ponto (y) ao vetor de médias(mi)',\n'-----------------------------------------------------------------';\nprint ,,Y ' ' DM2[format=8.4] ' ' rank;\nquit;\n\nproc corr cov data=cork;\ntitle 'Matriz de variâncias e covariâncias utilizando proc corr';\nvar north east south west;\nrun;"
  },
  {
    "objectID": "exemplo2.1.html",
    "href": "exemplo2.1.html",
    "title": "\n2  Gráfico da Normal Bivariada\n",
    "section": "",
    "text": "Construiremos o gráfico da normal bivariada utilizando o pacote plotly. Este pacote permite confeccionar gráficos dinâmicos tridimensionais.\n\ninstall.packages(\"plotly\")\n\n\nlibrary(plotly)\n\n\n\nR\nSAS\n\n\n\nPara construir o gráfico da normal bivariada, primeiramente, definimos os valores dos vetores das variáveis y1 e y2.\n\ny1 &lt;- seq(from = -4, to = 4, by = 0.1)\ny1\n\n [1] -4.0 -3.9 -3.8 -3.7 -3.6 -3.5 -3.4 -3.3 -3.2 -3.1 -3.0 -2.9 -2.8 -2.7 -2.6\n[16] -2.5 -2.4 -2.3 -2.2 -2.1 -2.0 -1.9 -1.8 -1.7 -1.6 -1.5 -1.4 -1.3 -1.2 -1.1\n[31] -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2  0.3  0.4\n[46]  0.5  0.6  0.7  0.8  0.9  1.0  1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9\n[61]  2.0  2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4\n[76]  3.5  3.6  3.7  3.8  3.9  4.0\n\ny2 &lt;- seq(from = -4, to = 4, by = 0.1)\ny2\n\n [1] -4.0 -3.9 -3.8 -3.7 -3.6 -3.5 -3.4 -3.3 -3.2 -3.1 -3.0 -2.9 -2.8 -2.7 -2.6\n[16] -2.5 -2.4 -2.3 -2.2 -2.1 -2.0 -1.9 -1.8 -1.7 -1.6 -1.5 -1.4 -1.3 -1.2 -1.1\n[31] -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.0  0.1  0.2  0.3  0.4\n[46]  0.5  0.6  0.7  0.8  0.9  1.0  1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9\n[61]  2.0  2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4\n[76]  3.5  3.6  3.7  3.8  3.9  4.0\n\n\nA função seq() cria uma sequência de valores e possui três argumentos:\n\nfrom =: valor em que a sequência começa;\nto =: valor em que a sequência termina;\nby =: de quanto em quanto a sequência é construída.\n\nEm seguida, calculamos a densidade bivariada, dada pela seguinte equação:\n\\[\n\\phi = \\frac{1}{2\\pi \\sqrt{1-r^2}} exp\\left\\{-\\frac{y_1^2 - 2r y_1 y_2 + y_2^2}{2(1-r^2)}\\right\\}\n\\]\nem que \\(r\\) é o coeficiente de correlação entre y1 e y2, variando de -1 a 1.\nO valor do coeficiente de correlação será salvo no objeto r. Já o objeto pi armazena o valor de \\(\\pi\\) com seis casas decimais.\nPara verificar as alterações gráficas, redefina o valor do objeto r (valor entre -1 e 1).\n\nr &lt;- -0.75  # Modificar este valor para verificar as alterações gráficas\npi\n\n[1] 3.141593\n\n\nPara realizar o cálculo da densidade bivariada no R, criamos uma função (function()) que executa a equação definida anteriormente para cada um dos valores de y1 e y2, gerando a matriz final, salva no objeto z.\n\nz &lt;- outer(y1, y2, function(y1,y2) { \n  phi &lt;- 1/(2 * pi * sqrt(1 - r^2)) * exp(-(y1^2 - 2 * r * y1 * y2 + y2^2) / (2 * (1 - r^2)))\n  return(phi)\n})\n\nCom isso, podemos criar o gráfico de densidade bivariada.\n\nplot_ly(x = y1, y = y2, z = z, type = \"surface\") |&gt; \n  layout(title = paste(\"Densidade Normal Bivariada (r =\", r, \")\"))\n\n\n\n\n\nCom a função plot_ly(), definimos os objetos que compõem os eixos x, y e z, além do estilo do gráfico (type = \"surface\"). Em seguida, utilizando a função layout(), inserimos o título do gráfico.\nLink para aplicativo dinâmico: https://gustavojy.github.io/n-multi-graph-app/.\n\n\n\n%let r=-0.75; * Fixa o coeficiente de correlação entre y1 e y2;\ndata Normal;\n pi=3.1416;\n do y1=-4 to 4 by 0.1;\n  do y2=-4 to 4 by 0.1; \n  phi=exp(-(y1*y1-2*&r*y1*y2+y2*y2)/2/(1-&r*&r))/2/pi/sqrt(1-&r*&r);\n  output;\n  end;\n end;\nrun;\n\ngoptions reset=all border;\nproc g3d data=Normal;\n title 'Densidade Normal Bivariada (r =' &r ')';\n plot y1*y2=phi / rotate=-20;\nrun;"
  },
  {
    "objectID": "exemplo2.2.html#exemplo-1-4.4a",
    "href": "exemplo2.2.html#exemplo-1-4.4a",
    "title": "\n3  Propriedades\n",
    "section": "\n3.1 Exemplo 1 (4.4(a))",
    "text": "3.1 Exemplo 1 (4.4(a))\nPara os exemplos dos Teoremas 1, 2 e 3 considere um vetor aleatório \\(\\mathbf{y} \\sim N_3(\\mathbf{\\mu}, \\mathbf{\\Sigma})\\), em que:\n\\[\n\\mathbf{\\mu} =\n  \\begin{bmatrix}\n  3 \\\\ 1 \\\\ 2\n  \\end{bmatrix}\n\\space e \\space\n\\mathbf{\\Sigma} =\n  \\begin{bmatrix}\n   4 & 0 & 2 \\\\\n   0 & 1 & -1 \\\\\n   2 & -1 & 3 \\\\\n   \\end{bmatrix}\n\\]\n\n\nR\nSAS\n\n\n\n\nmi &lt;- c(3, 1, 2)\nmi\n\n[1] 3 1 2\n\nSigma &lt;- matrix(c(4, 0, 2, 0, 1, -1, 2, -1, 3), nrow = 3, ncol = 3)\nSigma\n\n     [,1] [,2] [,3]\n[1,]    4    0    2\n[2,]    0    1   -1\n[3,]    2   -1    3\n\n\n\n\n\noptions nocenter ps=1000;\nproc iml;\nreset fuzz;\n\ny = {'y1','y2','y3'};\nmi = {3,1,2};\nSigma = {4 0 2, 0 1 -1, 2 -1 3};\n\n\n\n\n\n3.1.1 Teorema 1.1 (4.4A. i)\nSejam \\(\\mathbf{y} \\sim N_p(\\mathbf{\\mu}, \\mathbf{\\Sigma})\\) e \\(\\mathbf{a}\\) um vetor \\(p \\times 1\\) de constantes. Então, a variável aleatória:\n\\[z = \\mathbf{a'}\\mathbf{y} \\sim N(\\mathbf{a' \\mu}, \\mathbf{a'\\Sigma a})\\]\nComo exemplo, considere:\n\\[\nz = y_1 - 2y_2 + y_3\n\\text{ ,   em que }\n\\mathbf{a} =\n  \\begin{bmatrix}\n    1 \\\\ -2 \\\\ 1\n  \\end{bmatrix}\n\\]\n\n\nR\nSAS\n\n\n\n\na &lt;- c(1, -2, 1)\na\n\n[1]  1 -2  1\n\nE_z &lt;- t(a) %*% mi\nE_z\n\n     [,1]\n[1,]    3\n\nvar_z &lt;- t(a) %*% Sigma %*% a\nvar_z\n\n     [,1]\n[1,]   19\n\n\nCom isso, a variável aleatória \\(z\\) fica:\n\\[z = \\mathbf{a'y} \\sim N(\\mathbf{a' \\mu} = 3, \\mathbf{a'\\Sigma a} = 19)\\]\n\n\n\na = {1, -2, 1};\nmi_z = t(a) * mi;\nvar_z = t(a)*Sigma*a;\nprint y mi Sigma,,,,, 'item (i)   ',,'z = y1-2y2+y3   ' mi_z var_z;\n\n\n\n\n\n3.1.2 Teorema 1.2 (4.4A. ii)\nSejam \\(\\mathbf{y} \\sim N_p(\\mathbf{\\mu}, \\mathbf{\\Sigma})\\) e \\(\\mathbf{A}\\) uma matriz \\(k \\times p\\) de constantes e posto \\(k \\le p\\). Então, o vetor aleatório:\n\\[\\mathbf{z} = \\mathbf{A} \\mathbf{y} \\sim N_k(\\mathbf{A \\mu}, \\mathbf{A\\Sigma A'})\\]\nAgora, considere as seguintes combinações lineares \\(z_1\\) e \\(z_2\\):\n\\[\n\\begin{aligned}\nz_1 = y_1 - y_2 + y_3 \\space \\text{ e } \\space z_2 = 3y_1 + y_2 - 2y_3 \\\\\n\\mathbf{z} =\n\\begin{bmatrix}\n\\mathbf{z_1} \\\\ \\mathbf{z_2}\n\\end{bmatrix}\n\\text{ = }\n\\begin{bmatrix}\n1 & -1 & 1 \\\\\n3 & 1 & -2\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ y_3\n\\end{bmatrix}\n\\text{ = }\n\\mathbf{Ay}\n\\end{aligned}\n\\]\n\n\nR\nSAS\n\n\n\n\nA &lt;- matrix(c(1, -1, 1, 3, 1, -2), nrow = 2, ncol = 3, byrow = TRUE)\nA\n\n     [,1] [,2] [,3]\n[1,]    1   -1    1\n[2,]    3    1   -2\n\nE_z1z2 &lt;- A %*% mi\nE_z1z2\n\n     [,1]\n[1,]    4\n[2,]    6\n\ncov_z1z2 &lt;- A %*% Sigma %*% t(A)\ncov_z1z2\n\n     [,1] [,2]\n[1,]   14    4\n[2,]    4   29\n\n\nPelo teorema, o vetor aleatório fica:\n\\[\n\\mathbf{z} = \\mathbf{Ay} \\sim N_2\n\\left(\n  \\mathbf{A \\mu} =\n    \\begin{bmatrix}\n      4 \\\\ 6\n    \\end{bmatrix},\n  \\mathbf{A\\Sigma A'} =\n    \\begin{bmatrix}\n      14 & 4 \\\\\n      4 & 29\n    \\end{bmatrix}\n\\right)\n\\]\n\n\n\nZZ = {'z1 = y1-y2+y3','z2 = 3y1+y2-2y3'}; \nA = {1 -1  1, 3  1 -2};\nmi_ZZ = A*mi;\nSigma_ZZ = A*Sigma*t(A);\nprint 'item (ii)',,  ZZ '     ' mi_ZZ '     ' Sigma_ZZ;\n\n\n\n\n\n3.1.3 Teorema 2 (4.4B.)\nSe \\(\\mathbf{y} \\sim N_p(\\mathbf{\\mu, \\Sigma})\\), então qualquer subvetor \\(r \\times 1\\) de \\(\\mathbf{y}\\) tem uma distribuição normal \\(r\\)-variada com médias, variâncias e covariâncias iguais às da distribuição normal \\(p\\)-variada original.\nComo exemplo, considere: \\(y_1 \\sim N(3,4)\\), \\(y_2 \\sim N(1,1)\\) e \\(y_3 \\sim N(2, 3)\\).\n\n\nR\nSAS\n\n\n\nDessa forma, o vetor \\(\\begin{bmatrix} y_1 \\\\ y_2\\end{bmatrix}\\):\n\nA12 &lt;- matrix(c(1, 0, 0, 0, 1, 0), nrow = 2, ncol = 3, byrow = TRUE)\nA12\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n\nmi_12 &lt;- A12 %*% mi\nmi_12\n\n     [,1]\n[1,]    3\n[2,]    1\n\nSigma_12 &lt;- A12 %*% Sigma %*% t(A12)\nSigma_12\n\n     [,1] [,2]\n[1,]    4    0\n[2,]    0    1\n\n\n\\[\n\\begin{bmatrix}\n  y_1 \\\\ y_2\n\\end{bmatrix}\n  \\sim N_2\\left(\n    \\begin{bmatrix}\n      3 \\\\ 1\n    \\end{bmatrix},\n    \\begin{bmatrix}\n      4 & 0 \\\\\n      0 & 1\n    \\end{bmatrix}\n  \\right) \\\\\n\\]\nEnquanto isso, o vetor \\(\\begin{bmatrix} y_1 \\\\ y_3\\end{bmatrix}\\):\n\nA13 &lt;- matrix(c(1, 0, 0, 0, 0, 1), nrow = 2, ncol = 3, byrow = TRUE)\nA13\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    0    1\n\nmi_13 &lt;- A13 %*% mi\nmi_13\n\n     [,1]\n[1,]    3\n[2,]    2\n\nSigma_13 &lt;- A13 %*% Sigma %*% t(A13)\nSigma_13\n\n     [,1] [,2]\n[1,]    4    2\n[2,]    2    3\n\n\n\\[\n\\begin{bmatrix}\n  y_1 \\\\ y_3\n\\end{bmatrix}\n  \\sim N_2\\left(\n    \\begin{bmatrix}\n      3 \\\\ 2\n    \\end{bmatrix},\n    \\begin{bmatrix}\n      4 & 2 \\\\\n      2 & 3\n    \\end{bmatrix}\n  \\right)\n\\]\n\n\n\nA12 = {1 0 0, 0 1 0};\nmi_12 = A12*mi;\nSigma_12 = A12*Sigma*t(A12);\nprint mi_12 Sigma_12;\n\nA13 = {1 0 0, 0 0 1};\nmi_13 = A13*mi;\nSigma_13 = A13*Sigma*t(A13);\nprint mi_13 Sigma_13;\n\n\n\n\n\n3.1.4 Teorema 3 (4.4C.)\nSe o vetor particionado \\(\\mathbf{v} = \\begin{bmatrix} \\mathbf{y} \\\\ \\mathbf{x} \\end{bmatrix} \\sim N_{p+q}(\\mathbf{\\mu, \\Sigma})\\) então os subvetores aleatórios \\(\\mathbf{y}\\) e \\(\\mathbf{x}\\) são independentes se \\(\\mathbf{\\Sigma}_{xy} = 0\\).\n\n\nR\nSAS\n\n\n\n\na1 &lt;- c(1, 0, 0)\na1\n\n[1] 1 0 0\n\nb2 &lt;- c(0, 1, 0)\nb2\n\n[1] 0 1 0\n\ncov_12 &lt;- t(a1) %*% Sigma %*% b2\ncov_12\n\n     [,1]\n[1,]    0\n\n\n\n\n\na1 = {1 0 0};\nb2 = {0 1 0};\ncov_12 = a1*Sigma*t(b2);\nprint cov_12;"
  },
  {
    "objectID": "exemplo2.2.html#exemplo-2-4.4b",
    "href": "exemplo2.2.html#exemplo-2-4.4b",
    "title": "\n3  Propriedades\n",
    "section": "\n3.2 Exemplo 2 (4.4(b))",
    "text": "3.2 Exemplo 2 (4.4(b))\n\n3.2.1 Teorema 4 (4.4D.)\nSe \\(\\mathbf{y}\\) e \\(\\mathbf{x}\\) têm distribuição conjunta normal multivariada com \\(\\mathbf{\\Sigma}_{yx} \\ne 0\\) então a distribuição condicional de \\(\\mathbf{y}\\) dado \\(\\mathbf{x}\\), \\(f(\\mathbf{y} \\mid \\mathbf{x})\\), é normal multivariada com vetor de médias e matriz de covariâncias dados por:\n\\[\n\\begin{aligned}\nE(\\mathbf{y} \\mid \\mathbf{x}) = \\mathbf{\\mu}_y + \\mathbf{\\Sigma}_{yx} \\mathbf{\\Sigma}_{xx}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_x) \\\\\ncov(\\mathbf{y} \\mid \\mathbf{x}) = \\mathbf{\\Sigma}_{yy} - \\mathbf{\\Sigma}_{yx} \\mathbf{\\Sigma}_{xx}^{-1} \\mathbf{\\Sigma}_{xy}\n\\end{aligned}\n\\]\nPara ilustrar o Teorema 4 (4.4D.), considere o vetor aleatório \\(\\mathbf{v} \\sim N_4(\\mathbf{\\mu, \\Sigma})\\) em que:\n\\[\n\\begin{aligned}\n\\mathbf{\\mu} =\n\\begin{bmatrix}\n2 \\\\ 5 \\\\ -2 \\\\ 1\n\\end{bmatrix}\n\\text{ e }\n\\mathbf{\\Sigma} =\n\\begin{bmatrix}\n9 & 0 & 3 & 3 \\\\\n0 & 1 & -1 & 2 \\\\\n3 & -1 & 6 & -3 \\\\\n3 & 2 & -3 & 7 \\\\\n\\end{bmatrix}\n\\end{aligned}\n\\]\n\n\nR\nSAS\n\n\n\n\nmi &lt;- c(2, 5, -2, 1)\nmi\n\n[1]  2  5 -2  1\n\nSigma &lt;- matrix(\n  c(9, 0, 3, 3, 0, 1, -1, 2, 3, -1, 6, -3, 3, 2, -3, 7), \n  nrow = 4, byrow = TRUE\n  )\nSigma\n\n     [,1] [,2] [,3] [,4]\n[1,]    9    0    3    3\n[2,]    0    1   -1    2\n[3,]    3   -1    6   -3\n[4,]    3    2   -3    7\n\n\n\n\n\noptions nocenter ps=1000;\nproc iml;\nreset fuzz;\n\nmi = {2,5,-2,1};\nSigma = {9 0 3 3, 0 1 -1 2, 3 -1 6 -3, 3 2 -3 7};\nprint v mi Sigma;\n\n\n\n\nSe \\(\\mathbf{v} = \\begin{bmatrix} y_1, y_2, x_1, x_2 \\end{bmatrix} '\\) é um vetor particionado dessa forma, então:\n\\[\n\\mathbf{\\mu_y} =\n\\begin{bmatrix}\n2 \\\\ 5\n\\end{bmatrix}\n,\n\\mathbf{\\mu_x} =\n\\begin{bmatrix}\n-2 \\\\ 1\n\\end{bmatrix} \\\\\n\\]\n\\[\n\\mathbf{\\Sigma_{yy}} =\n\\begin{bmatrix}\n9 & 0 \\\\ 0 & 1\n\\end{bmatrix}\n,\n\\mathbf{\\Sigma_{xx}}\n\\begin{bmatrix}\n6 & -3 \\\\ -3 & 7\n\\end{bmatrix}\n,\n\\mathbf{\\Sigma_{yx}}\n\\begin{bmatrix}\n3 & 3 \\\\ -1 & 2\n\\end{bmatrix}\n\\]\n\n\nR\nSAS\n\n\n\n\nAy &lt;- matrix(c(1, 0, 0, 0, 0, 1, 0, 0), nrow = 2, byrow = TRUE)\nAy\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    0    0    0\n[2,]    0    1    0    0\n\nmi_y &lt;- Ay %*% mi\nmi_y\n\n     [,1]\n[1,]    2\n[2,]    5\n\nSigma_yy &lt;- Ay %*% Sigma %*% t(Ay)\nSigma_yy\n\n     [,1] [,2]\n[1,]    9    0\n[2,]    0    1\n\nAx &lt;- matrix(c(0, 0, 1, 0, 0, 0, 0, 1), nrow = 2, byrow = TRUE)\nAx\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    0    1    0\n[2,]    0    0    0    1\n\nmi_x &lt;- Ax %*% mi\nmi_x\n\n     [,1]\n[1,]   -2\n[2,]    1\n\nSigma_xx &lt;- Ax %*%Sigma %*% t(Ax)\nSigma_xx\n\n     [,1] [,2]\n[1,]    6   -3\n[2,]   -3    7\n\nSigma_yx &lt;- Ay %*% Sigma %*% t(Ax)\nSigma_yx\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   -1    2\n\n\n\n\n\nAy = {1 0 0 0, 0 1 0 0};\nmi_y = Ay*mi;\nSigma_yy = Ay*Sigma*t(Ay);\n\nAx = {0 0 1 0, 0 0 0 1};\nmi_x = Ax*mi;\nSigma_xx = Ax*Sigma*t(Ax);\n\nSigma_yx = Ay*Sigma*t(Ax);\nprint mi_y Sigma_yy,, mi_x Sigma_xx,, Sigma_yx;\n\n\n\n\nPara calcular \\(cov(\\mathbf{y} \\mid \\mathbf{x}) = \\mathbf{\\Sigma}_{yy} - \\mathbf{\\Sigma}_{yx} \\mathbf{\\Sigma}_{xx}^{-1} \\mathbf{\\Sigma}_{xy}\\) procedemos da seguinte maneira:\n\n\nR\nSAS\n\n\n\n\ncov_ydx &lt;- Sigma_yy - Sigma_yx %*% solve(Sigma_xx) %*% t(Sigma_yx)\ncov_ydx\n\n           [,1]       [,2]\n[1,]  3.8181818 -0.7272727\n[2,] -0.7272727  0.4242424\n\n\n\\[\ncov(\\mathbf{y} \\mid \\mathbf{x}) =\n\\begin{bmatrix}\n3,82 & -0,73 \\\\ -0,73 & 0,42\n\\end{bmatrix}\n\\]\n\n\n\ncov_ydx = Sigma_yy-Sigma_yx*inv(Sigma_xx)*t(Sigma_yx);\n\nprint Sigma_yy[format=6.0],, cov_ydx[format=6.2];\n\n\n\n\nNote que a variância de \\(y_1\\) e de \\(y_2\\) são maiores do que as variâncias condicionais:\n\nSigma_yy\n\n     [,1] [,2]\n[1,]    9    0\n[2,]    0    1\n\ncov_ydx\n\n           [,1]       [,2]\n[1,]  3.8181818 -0.7272727\n[2,] -0.7272727  0.4242424\n\n\n\\[\n\\begin{aligned}\nvar(y_1) = 9 \\text{ e } var(y_1 \\mid x_1, x_2) = 3,82 \\\\\nvar(y_2) = 1 \\text{ e } var(y_2 \\mid x_1, x_2) = 0,42\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "exemplo2.2.html#exemplo-3-4.4c",
    "href": "exemplo2.2.html#exemplo-3-4.4c",
    "title": "\n3  Propriedades\n",
    "section": "\n3.3 Exemplo 3 (4.4(c))",
    "text": "3.3 Exemplo 3 (4.4(c))\n\n3.3.1 Teorema 4 (4.4D.) - Corolário 1\nConsidere:\n\\[\n\\mathbf{v} =\n\\begin{bmatrix}\ny, & x_1, & \\dots, & x_q\n\\end{bmatrix}\n' =\n\\begin{bmatrix}\ny \\\\ \\mathbf{x'}\n\\end{bmatrix}\n\\text{ com }\n\\mathbf{\\mu} =\n\\begin{bmatrix}\n\\mu_y \\\\ \\mathbf{\\mu_x}\n\\end{bmatrix}\n\\text{ e }\n\\mathbf{\\Sigma} =\n\\begin{bmatrix}\n\\sigma_y^2 & \\mathbf{\\sigma}_{yx}' \\\\\n\\mathbf{\\sigma}_{yx} & \\mathbf{\\Sigma}_{xx}\n\\end{bmatrix}\n\\text{, }\n\\]\nentão \\(y \\mid \\mathbf{x}\\) tem distribuição normal univariada com:\n\\[\n\\begin{aligned}\nE(y \\mid \\mathbf{x}) = \\mu_y + \\mathbf{\\sigma}_{yx}' \\mathbf{\\Sigma}_{xx}^{-1} (\\mathbf{x} - \\mathbf{\\mu}_x) \\\\\nvar(y \\mid \\mathbf{x}) = \\sigma_{y}^2 - \\mathbf{\\sigma}_{yx}' \\mathbf{\\Sigma}_{xx}^{-1} \\mathbf{\\sigma}_{yx}\n\\end{aligned}\n\\]\nComo exemplo, seguimos com o vetor \\(\\mathbf{v}\\) utilizado no Teorema 4 (4.4D) 3.2.1.\n\\[\n\\mathbf{v} \\sim N_4(\\mathbf{\\mu}, \\mathbf{\\Sigma})\n\\text{ , }\n\\mathbf{\\mu} =\n\\begin{bmatrix}\n2 \\\\ 5 \\\\ -2 \\\\ 1\n\\end{bmatrix}\n\\text{ e }\n\\mathbf{\\Sigma} =\n\\begin{bmatrix}\n9 & 0 & 3 & 3 \\\\\n0 & 1 & -1 & 2 \\\\\n3 & -1 & 6 & -3 \\\\\n3 & 2 & -3 & 7 \\\\\n\\end{bmatrix}\n\\]\n\n\nR\nSAS\n\n\n\n\nmi &lt;- c(2, 5, -2, 1)\nmi\n\n[1]  2  5 -2  1\n\nSigma &lt;- matrix(\n  c(9, 0, 3, 3, 0, 1, -1, 2, 3, -1, 6, -3, 3, 2, -3, 7), \n  nrow = 4, byrow = TRUE\n  )\nSigma\n\n     [,1] [,2] [,3] [,4]\n[1,]    9    0    3    3\n[2,]    0    1   -1    2\n[3,]    3   -1    6   -3\n[4,]    3    2   -3    7\n\n\n\n\n\noptions nocenter ps=1000;\nproc iml;\nreset fuzz;\n\nmi = {2,5,-2,1};\nSigma = {9 0 3 3, 0 1 -1 2, 3 -1 6 -3, 3 2 -3 7};\nprint v mi Sigma;\n\n\n\n\nSe \\(\\mathbf{v} = \\begin{bmatrix} y, & x_1, & x_2, & x_3 \\end{bmatrix}'\\) então:\n\\[\\mu_y = 2 \\text{ e } var(y) = 9 \\\\\\]\n\\[\n\\mathbf{\\mu}_x =\n\\begin{bmatrix}\n5 \\\\ -2 \\\\ 1\n\\end{bmatrix}\n\\text{ , }\n\\mathbf{\\Sigma}_{xx} =\n\\begin{bmatrix}\n1 & -1 & 2 \\\\\n-1 & 6 & -3 \\\\\n2 & -3 & 7\n\\end{bmatrix}\n\\text{ e }\n\\mathbf{\\sigma}_{yx} =\n\\begin{bmatrix}\n0 \\\\ 3 \\\\ 3\n\\end{bmatrix}\n\\]\n\n\nR\nSAS\n\n\n\n\nAy &lt;- matrix(c(1, 0, 0, 0), nrow = 1)\nAy\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    0    0    0\n\nmi_y &lt;- Ay %*% mi\nmi_y\n\n     [,1]\n[1,]    2\n\nSigma_yy &lt;- Ay %*% Sigma %*% t(Ay)\nSigma_yy\n\n     [,1]\n[1,]    9\n\nAx &lt;- matrix(\n  c(0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1), \n  nrow = 3, ncol = 4, byrow = TRUE\n)\nAx\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    1    0    0\n[2,]    0    0    1    0\n[3,]    0    0    0    1\n\nmi_x &lt;- Ax %*% mi\nmi_x\n\n     [,1]\n[1,]    5\n[2,]   -2\n[3,]    1\n\nSigma_xx &lt;- Ax %*% Sigma %*% t(Ax)\nSigma_xx\n\n     [,1] [,2] [,3]\n[1,]    1   -1    2\n[2,]   -1    6   -3\n[3,]    2   -3    7\n\nsigma_yx &lt;- Ay %*% Sigma %*% t(Ax)\nsigma_yx\n\n     [,1] [,2] [,3]\n[1,]    0    3    3\n\n\n\n\n\nAy = {1 0 0 0};\nmi_y = Ay*mi;\nSigma_yy = Ay*Sigma*t(Ay);\n\nAx = {0 1 0 0, 0 0 1 0, 0 0 0 1};\nmi_x = Ax*mi;\nSigma_xx = Ax*Sigma*t(Ax);\n\nSigma_yx = Ay*Sigma*t(Ax);\nprint mi_y Sigma_yy,, mi_x Sigma_xx,, Sigma_yx;\n\n\n\n\nPelo Corolário, temos:\n\\[\nvar(y \\mid x_1, x_2, x_3) = \\sigma_{y}^2 - \\mathbf{\\sigma}_{yx}' \\mathbf{\\Sigma}_{xx}^{-1} \\mathbf{\\sigma}_{yx}\n\\]\n\n\nR\nSAS\n\n\n\n\ncov_ydx &lt;- Sigma_yy - sigma_yx %*% solve(Sigma_xx) %*% t(sigma_yx)\ncov_ydx\n\n         [,1]\n[1,] 2.571429\n\n\nPortanto, \\(var(y \\mid x_1, x_2, x_3) = 2.571\\).\nNote que a variância de \\(y\\) é maior do que a variância condicional:\n\nSigma_yy\n\n     [,1]\n[1,]    9\n\ncov_ydx\n\n         [,1]\n[1,] 2.571429\n\n\n\\[\n\\begin{aligned}\nvar(y) &= 9 \\\\\nvar(y \\mid x_1, x_2, x_3) &= 2.571\n\\end{aligned}\n\\]\n\n\n\ncov_ydx = Sigma_yy-Sigma_yx*inv(Sigma_xx)*t(Sigma_yx);\n\nprint Sigma_yy[format=6.0],, cov_ydx[format=6.2];"
  },
  {
    "objectID": "exemplo2.3.html",
    "href": "exemplo2.3.html",
    "title": "\n4  Correlação Parcial\n",
    "section": "",
    "text": "Considere um vetor \\(\\mathbf{v}\\), formado por um subconjunto de \\(y's\\) que inclui \\(y_1\\) e \\(y_2\\), sendo denotado por \\(\\mathbf{y}\\). O outro subconjunto de \\(y's\\) que inclui \\(y_3\\) e \\(y_4\\) é denotado por \\(\\mathbf{x}\\).\n\\[\n\\mathbf{v} =\n\\begin{bmatrix}\n\\mathbf{y} \\\\ \\mathbf{x}\n\\end{bmatrix}\n\\text{, em que }\n\\mathbf{y} =\n\\begin{bmatrix}\ny_1, ..., y_2\n\\end{bmatrix}\n\\text{'  e  }\n\\mathbf{x} =\n\\begin{bmatrix}\ny_3, ..., y_4\n\\end{bmatrix}\n\\text{'}\n\\]\nVamos comparar o coeficiente de correlação parcial entre \\(y_1\\) e \\(y_2\\) (\\(\\rho_{12}\\)) com o coeficiente de correlação parcial condicional de \\(y_1\\) e \\(y_2\\) dado \\(y_3\\) e \\(y_4\\) (\\(\\rho_{12.34}\\)).\nPara isso, utilizaremos a seguinte matriz de variâncias e covariâncias:\n\\[\n\\mathbf{\\Sigma} =\n  \\begin{bmatrix}\n    9 & 0 & 3 & 3 \\\\\n    0 & 1 & -1 & 2 \\\\\n    3 & -1 & 6 & -3 \\\\\n    3 & 2 & -3 & 7 \\\\\n   \\end{bmatrix}\n\\text{.}\n\\]\nPrimeiramente, calcularemos a correlação linear entre as variáveis \\(y_1\\) e \\(y_2\\), ou seja, \\(\\rho_{12}\\).\n\n\nR\nSAS\n\n\n\nCom a matriz de variâncias e covariâncias salva no objeto Sigma, calculamos a raiz quadrada da diagonal de Sigma, ou seja, a raiz quadrada das variâncias (D).\n\nSigma &lt;- matrix(\n  c(9, 0, 3, 3, 0, 1, -1, 2, 3, -1, 6, -3, 3, 2, -3, 7), \n  nrow = 4, byrow = TRUE\n)\nSigma\n\n     [,1] [,2] [,3] [,4]\n[1,]    9    0    3    3\n[2,]    0    1   -1    2\n[3,]    3   -1    6   -3\n[4,]    3    2   -3    7\n\nD &lt;- sqrt(diag(Sigma))\nD\n\n[1] 3.000000 1.000000 2.449490 2.645751\n\n\nCom a raiz quadrada das variâncias (D), calculamos os coeficientes de correlação por meio da seguinte expressão:\n\\[\\mathbf{\\rho} = \\mathbf{D}_{\\sigma}^{-1} \\mathbf{\\Sigma} \\mathbf{D}_{\\sigma}^{-1}\\]\n\nRo &lt;- solve(diag(D)) %*% Sigma %*% solve(diag(D))\nRo\n\n          [,1]       [,2]       [,3]       [,4]\n[1,] 1.0000000  0.0000000  0.4082483  0.3779645\n[2,] 0.0000000  1.0000000 -0.4082483  0.7559289\n[3,] 0.4082483 -0.4082483  1.0000000 -0.4629100\n[4,] 0.3779645  0.7559289 -0.4629100  1.0000000\n\n\nAssim, verificamos que as variáveis \\(y_1\\) e \\(y_2\\) são não correlacionadas (\\(\\rho_{12} = \\rho_{21} = 0\\)).\n\n\n\noptions nocenter ps=1000;\nproc iml;\nreset fuzz;\n\nSigma = {9  0  3  3, \n         0  1 -1  2, \n         3 -1  6 -3, \n         3  2 -3  7};\nD = sqrt(diag(Sigma));\nRo = inv(D)*Sigma*inv(D);\nprint Sigma '     ' Ro[format=6.2];\n\n\n\n\nPara calcular o coeficiente de correlação parcial entre \\(y_1\\) e \\(y_2\\) dada a condicional \\(y_3\\) e \\(y_4\\) (\\(\\rho_{12.34}\\)), particionaremos \\(\\Sigma\\) da seguinte maneira:\n\\[\n\\mathbf{\\Sigma}_{yy} =\n  \\begin{bmatrix}\n    9 & 0 \\\\\n    0 & 1\n  \\end{bmatrix}\n\\text{  ,  }\n\\mathbf{\\Sigma}_{xx} =\n  \\begin{bmatrix}\n    6 & -3 \\\\\n    -3 & 7\n  \\end{bmatrix}\n,\\mathbf{\\Sigma}_{yx} =\n  \\begin{bmatrix}\n    3 & 3 \\\\\n    -1 & 2\n  \\end{bmatrix}\n\\]\n\n\nR\nSAS\n\n\n\nPara particionar \\(\\mathbf{\\Sigma}\\), utilizaremos o Teorema 2 (4.4B.) 3.1.3.\nA primeira partição (\\(\\mathbf{\\Sigma}_{yy}\\)) fica:\n\nAy &lt;- matrix(c(1, 0, 0, 0, 0, 1, 0, 0), nrow = 2, byrow = TRUE)\nAy\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    0    0    0\n[2,]    0    1    0    0\n\nSigma_yy &lt;- Ay %*% Sigma %*% t(Ay)\nSigma_yy\n\n     [,1] [,2]\n[1,]    9    0\n[2,]    0    1\n\n\nNote que esta partição corresponde ao \\(\\rho_{12} = 0\\):\n\nDyy &lt;- sqrt(diag(Sigma_yy))\nDyy\n\n[1] 3 1\n\nRo_yy &lt;- solve(diag(Dyy)) %*% Sigma_yy %*% solve(diag(Dyy))\nRo_yy\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n\nPara a partição \\(\\mathbf{\\Sigma}_{xx}\\) temos:\n\nAx &lt;- matrix(c(0, 0, 1, 0, 0, 0, 0, 1), nrow = 2, byrow = TRUE)\nAx\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    0    1    0\n[2,]    0    0    0    1\n\nSigma_xx &lt;- Ax %*% Sigma %*% t(Ax)\nSigma_xx\n\n     [,1] [,2]\n[1,]    6   -3\n[2,]   -3    7\n\n\nPor fim, a partição \\(\\mathbf{\\Sigma}_{yx}\\):\n\nSigma_yx &lt;- Ay %*% Sigma %*% t(Ax)\nSigma_yx\n\n     [,1] [,2]\n[1,]    3    3\n[2,]   -1    2\n\n\nUsando o Teorema 4 (4.4D) 3.2.1, obtemos a matriz de covariâncias condicionais de \\(y_1\\) e \\(y_2\\) dado \\(y_3\\) e \\(y_4\\):\n\\[cov(y \\mid x) = \\mathbf{\\Sigma}_{yy} - \\mathbf{\\Sigma}_{yx} \\mathbf{\\Sigma}_{xx}^{-1} \\mathbf{\\Sigma}_{xy}\\]\n\ncov_ydx &lt;- Sigma_yy - Sigma_yx %*% solve(Sigma_xx) %*% t(Sigma_yx)\ncov_ydx\n\n           [,1]       [,2]\n[1,]  3.8181818 -0.7272727\n[2,] -0.7272727  0.4242424\n\n\nNote que \\(\\mathbf{\\Sigma}\\) é uma matriz simétrica, logo \\(\\mathbf{\\Sigma}_{yx} = \\mathbf{\\Sigma}'_{xy} \\iff \\mathbf{\\Sigma}_{xy} = \\mathbf{\\Sigma}'_{yx}\\).\nAssim, podemos calcular o coeficiente de correlação parcial \\(\\rho_{12.34}\\):\n\nD &lt;- sqrt(diag(cov_ydx))\nD\n\n[1] 1.9540168 0.6513389\n\nRo_ydx &lt;- solve(diag(D)) %*% cov_ydx %*% solve(diag(D))\nRo_ydx\n\n           [,1]       [,2]\n[1,]  1.0000000 -0.5714286\n[2,] -0.5714286  1.0000000\n\n\nPortanto, conhecendo os valores de \\(y_3\\) e \\(y_4\\), a correlação parcial entre \\(y_1\\) e \\(y_2\\) é negativa (\\(\\rho_{12.34} = -0,571\\)) e diferente da correlação linear simples (\\(\\rho_{12} = 0\\)).\n\nRo_yy\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\nRo_ydx\n\n           [,1]       [,2]\n[1,]  1.0000000 -0.5714286\n[2,] -0.5714286  1.0000000\n\n\n\n\n\nAy = {1 0 0 0, 0 1 0 0};\nSigma_yy = Ay*Sigma*t(Ay);\nDyy = sqrt(diag(Sigma_yy));\nRo_yy = inv(Dyy)*Sigma_yy*inv(Dyy);\n\nAx = {0 0 1 0, 0 0 0 1};\nSigma_xx = Ax*Sigma*t(Ax);\n\nSigma_yx = Ay*Sigma*t(Ax);\n\ncov_ydx = Sigma_yy-Sigma_yx*inv(Sigma_xx)*t(Sigma_yx);\nD = sqrt(diag(cov_ydx));\nRo_ydx = inv(D)*cov_ydx*inv(D);\n\nprint Ro_yy[format=8.2] '    ' Ro_ydx[format=8.3];"
  },
  {
    "objectID": "exemplo3.1.html#análise-exploratória",
    "href": "exemplo3.1.html#análise-exploratória",
    "title": "\n5  Regressão Linear Simples\n",
    "section": "\n5.1 Análise exploratória",
    "text": "5.1 Análise exploratória\nPara visualizar a dispersão dos dados, construiremos um gráfico de pontos (gráfico de dispersão) entre as notas dos alunos na prova (y) e nas tarefas de casa (x1). Para isso, utilizaremos os recursos do pacote ggplot2.\n\nlibrary(ggplot2)\n\n\nnotas &lt;- data.frame(y, x1)\nnotas\n\n    y x1\n1  95 96\n2  80 77\n3   0  0\n4   0  0\n5  79 78\n6  77 64\n7  72 89\n8  66 47\n9  98 90\n10 90 93\n11  0 18\n12 95 86\n13 35  0\n14 50 30\n15 72 59\n16 55 77\n17 75 74\n18 66 67\n\nggplot(data = notas, aes(x = x1, y = y)) +\n  geom_point()\n\n\n\n\nPrimeiramente, criamos um data frame com as notas dos alunos. Em seguida, com a função ggplot(), atribuímos a variável nota nas tarefas (x1) ao eixo das abscissas e a nota na prova (y) ao eixo das ordenadas. Com a geom_point(), adicionamos a camada gráfica referente à geometria de pontos, ou seja, a geometria do gráfico de dispersão. Note que as funções ggplot() e geom_point() são ligadas pelo operador +."
  },
  {
    "objectID": "exemplo3.1.html#estimação-dos-parâmetros-beta_0-e-beta_1",
    "href": "exemplo3.1.html#estimação-dos-parâmetros-beta_0-e-beta_1",
    "title": "\n5  Regressão Linear Simples\n",
    "section": "\n5.2 Estimação dos parâmetros \\(\\beta_0\\) e \\(\\beta_1\\)\n",
    "text": "5.2 Estimação dos parâmetros \\(\\beta_0\\) e \\(\\beta_1\\)\n\nPara estimar os parâmetros \\(\\beta_0\\) e \\(\\beta_1\\), utilizaremos o Método dos Mínimos Quadrados Ordinários (MQO). O método consiste em achar os estimadores \\(\\hat\\beta_0\\) e \\(\\hat\\beta_1\\) que minimizem a soma de quadrados dos desvios \\(y_i - \\hat{y}_i\\).\nPrimeiramente, criaremos os seguintes objetos:\n\nn: número de observações \\(n\\);\njn: vetor coluna de 1’s \\(\\mathbf{j}\\);\nJnn: matriz de 1’s \\(\\mathbf{J}\\);\nIn: matriz identidade \\(\\mathbf{I}\\).\n\n\n\nR\nSAS\n\n\n\n\nn &lt;- length(y)\nn\n\n[1] 18\n\njn &lt;- matrix(data = 1, nrow = n, ncol = 1)\njn\n\n      [,1]\n [1,]    1\n [2,]    1\n [3,]    1\n [4,]    1\n [5,]    1\n [6,]    1\n [7,]    1\n [8,]    1\n [9,]    1\n[10,]    1\n[11,]    1\n[12,]    1\n[13,]    1\n[14,]    1\n[15,]    1\n[16,]    1\n[17,]    1\n[18,]    1\n\nJnn &lt;- jn %*% t(jn)\nJnn\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n [1,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [2,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [3,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [4,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [5,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [6,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [7,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [8,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n [9,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[10,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[11,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[12,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[13,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[14,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[15,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[16,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[17,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n[18,]    1    1    1    1    1    1    1    1    1     1     1     1     1\n      [,14] [,15] [,16] [,17] [,18]\n [1,]     1     1     1     1     1\n [2,]     1     1     1     1     1\n [3,]     1     1     1     1     1\n [4,]     1     1     1     1     1\n [5,]     1     1     1     1     1\n [6,]     1     1     1     1     1\n [7,]     1     1     1     1     1\n [8,]     1     1     1     1     1\n [9,]     1     1     1     1     1\n[10,]     1     1     1     1     1\n[11,]     1     1     1     1     1\n[12,]     1     1     1     1     1\n[13,]     1     1     1     1     1\n[14,]     1     1     1     1     1\n[15,]     1     1     1     1     1\n[16,]     1     1     1     1     1\n[17,]     1     1     1     1     1\n[18,]     1     1     1     1     1\n\nIn &lt;- diag(n)\nIn\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n [1,]    1    0    0    0    0    0    0    0    0     0     0     0     0\n [2,]    0    1    0    0    0    0    0    0    0     0     0     0     0\n [3,]    0    0    1    0    0    0    0    0    0     0     0     0     0\n [4,]    0    0    0    1    0    0    0    0    0     0     0     0     0\n [5,]    0    0    0    0    1    0    0    0    0     0     0     0     0\n [6,]    0    0    0    0    0    1    0    0    0     0     0     0     0\n [7,]    0    0    0    0    0    0    1    0    0     0     0     0     0\n [8,]    0    0    0    0    0    0    0    1    0     0     0     0     0\n [9,]    0    0    0    0    0    0    0    0    1     0     0     0     0\n[10,]    0    0    0    0    0    0    0    0    0     1     0     0     0\n[11,]    0    0    0    0    0    0    0    0    0     0     1     0     0\n[12,]    0    0    0    0    0    0    0    0    0     0     0     1     0\n[13,]    0    0    0    0    0    0    0    0    0     0     0     0     1\n[14,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[15,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[16,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[17,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n[18,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n      [,14] [,15] [,16] [,17] [,18]\n [1,]     0     0     0     0     0\n [2,]     0     0     0     0     0\n [3,]     0     0     0     0     0\n [4,]     0     0     0     0     0\n [5,]     0     0     0     0     0\n [6,]     0     0     0     0     0\n [7,]     0     0     0     0     0\n [8,]     0     0     0     0     0\n [9,]     0     0     0     0     0\n[10,]     0     0     0     0     0\n[11,]     0     0     0     0     0\n[12,]     0     0     0     0     0\n[13,]     0     0     0     0     0\n[14,]     1     0     0     0     0\n[15,]     0     1     0     0     0\n[16,]     0     0     1     0     0\n[17,]     0     0     0     1     0\n[18,]     0     0     0     0     1\n\n\nA operação matricial para obter \\(\\hat\\beta_1\\) e \\(\\hat\\beta_0\\) é:\n\\[\n\\begin{align}\n\\hat\\beta_1 &= \\frac{\\left[\\mathbf{x}' \\left(\\mathbf{I} - \\frac{1}n \\mathbf{J} \\right) \\mathbf{y}\\right]} {\\left[\\mathbf{x}' \\left(\\mathbf{I} - \\frac{1}n \\mathbf{J} \\right) \\mathbf{x}\\right]} \\\\\n\\hat\\beta_0 &= \\frac{1}n \\mathbf{j}' (\\mathbf{y} - \\beta_1 \\mathbf{x})\n\\end{align}\n\\]\n\nBeta1 &lt;- as.numeric(t(x1) %*% (In - (1 / n) * Jnn) %*% y / (t(x1) %*% (In - (1 / n) * Jnn) %*% x1))\nBeta1\n\n[1] 0.8726465\n\nBeta0 &lt;- as.numeric((1 / n) * t(jn) %*% (y - Beta1 * x1))\nBeta0\n\n[1] 10.72691\n\n\nO R possui a função lm(), que nos retorna as estimativas dos parâmetros de um modelo linear. Para isso, dentro da função, colocamos os valores de y e x1 ligados pelo operador ~, que representa uma fórmula.\n\nlm(y ~ x1)\n\n\nCall:\nlm(formula = y ~ x1)\n\nCoefficients:\n(Intercept)           x1  \n    10.7269       0.8726  \n\n\nCom isso, a equação predita fica:\n\\[\\hat{y}_i = 10.7269 + 0.8726 x_i\\]\nGraficamente, temos:\n\nggplot(data = notas, aes(x = x1, y = y)) +\n  geom_point() + \n  geom_abline(intercept = 10.7269, slope = 0.8726, color = \"red\")\n\n\n\n\nCom a função geom_abline(), declaramos o \\(\\hat\\beta_0 = 10.7269\\) no argumento intercept = e \\(\\hat\\beta_1 = 0.8726\\) no argumento slope =.\nTambém podemos utilizar a função geom_smooth() para construir a reta de regressão. Essa função calcula, automaticamente, os valores do \\(\\hat\\beta_0\\) e \\(\\hat\\beta_1\\) para construir a reta.\n\nggplot(data = notas, aes(x = x1, y = y)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\n\n\n\nn = nrow(y);\njn = j(n,1,1);\nJnn = j(n,n,1);\nIn = I(n);\nX = jn||x1;\ny_barra = (1/n)*Jnn*y;\nTot = y-y_barra;\nSQTotal = t(Tot)*(Tot);\n* pág.135;\nBeta1 = t(x1)*(In-(1/n)*Jnn)*y/(t(x1)*(In-(1/n)*Jnn)*x1);\nBeta0 = (1/n)*t(jn)*(y - Beta1*x1);\nprint 'Estimativas dos parâmetros da reta:' Beta0[format=8.4] Beta1[format=8.4],,,;"
  },
  {
    "objectID": "exemplo3.1.html#estimação-da-variância-sigma2",
    "href": "exemplo3.1.html#estimação-da-variância-sigma2",
    "title": "\n5  Regressão Linear Simples\n",
    "section": "\n5.3 Estimação da variância (\\(\\sigma^2\\))",
    "text": "5.3 Estimação da variância (\\(\\sigma^2\\))\nPara estimar a variância \\(\\sigma^2\\), utilizamos a seguinte expressão:\n\\[\ns^2 =\n\\frac{(\\mathbf{y} - \\mathbf{\\hat{y}})' \\space (\\mathbf{y} - \\mathbf{\\hat{y}})}{n-2} =  \\frac{SQRes}{n-2}\n\\]\nEm que \\(SQRes\\) é a soma de quadrados dos resíduos e \\(\\hat{y}\\).\n\n\nR\nSAS\n\n\n\n\ny_hat &lt;- Beta0 + Beta1 * x1\ny_hat\n\n [1] 94.50098 77.92069 10.72691 10.72691 78.79334 66.57629 88.39245 51.74130\n [9] 89.26510 91.88304 26.43455 85.77451 10.72691 36.90631 62.21306 77.92069\n[17] 75.30275 69.19423\n\nRes &lt;- y - y_hat\nRes\n\n [1]   0.4990229   2.0793072 -10.7269091 -10.7269091   0.2066607  10.4237122\n [7] -16.3924513  14.2587034   8.7349022  -1.8830375 -26.4345469   9.2254883\n[13]  24.2730909  13.0936946   9.7869449 -22.9206928  -0.3027532  -3.1942274\n\nSQRes &lt;- t(Res) %*% Res\nSQRes\n\n         [,1]\n[1,] 3071.229\n\ns2 &lt;- as.numeric(SQRes / (n - 2))\ns2\n\n[1] 191.9518\n\n\nPara calcular o resíduo padronizado, dividimos o resíduo pelo desvio padrão da variância estimada (\\(\\sqrt{s^2}\\)).\n\nres_pad &lt;- Res / sqrt(s2)\nres_pad\n\n [1]  0.03601839  0.15007989 -0.77424509 -0.77424509  0.01491632  0.75236099\n [7] -1.18317166  1.02916236  0.63046633 -0.13591357 -1.90798839  0.66587578\n[13]  1.75197917  0.94507454  0.70640050 -1.65436600 -0.02185207 -0.23055242\n\n\n\n\n\n\nValores observados(`y`)\nValores estimados(`y_hat`)\nResíduo(`Res`)\nResíduo Padronizado(`res_pad`)\n\n\n\n95\n94.5010\n0.4990\n0.0360\n\n\n80\n77.9207\n2.0793\n0.1501\n\n\n0\n10.7269\n-10.7269\n-0.7742\n\n\n0\n10.7269\n-10.7269\n-0.7742\n\n\n79\n78.7933\n0.2067\n0.0149\n\n\n77\n66.5763\n10.4237\n0.7524\n\n\n72\n88.3925\n-16.3925\n-1.1832\n\n\n66\n51.7413\n14.2587\n1.0292\n\n\n98\n89.2651\n8.7349\n0.6305\n\n\n90\n91.8830\n-1.8830\n-0.1359\n\n\n0\n26.4345\n-26.4345\n-1.9080\n\n\n95\n85.7745\n9.2255\n0.6659\n\n\n35\n10.7269\n24.2731\n1.7520\n\n\n50\n36.9063\n13.0937\n0.9451\n\n\n72\n62.2131\n9.7869\n0.7064\n\n\n55\n77.9207\n-22.9207\n-1.6544\n\n\n75\n75.3028\n-0.3028\n-0.0219\n\n\n66\n69.1942\n-3.1942\n-0.2306\n\n\n\n\n\nVariância dos dados originais e desvio padrão estimado:\n\nvar_y &lt;- (t(y) %*% (In - (1/n) * Jnn) %*% y) / (n - 1)\nvar_y\n\n         [,1]\n[1,] 1055.546\n\ns &lt;- sqrt(s2)\ns\n\n[1] 13.85467\n\n\n\n\n\n\nVariância dos dados originais (`var_y`)\nVariância de y|x (`s2`)\nDesvio padrão de y|x (`s`)\n\n\n1055.546\n191.9518\n13.8547\n\n\n\n\n\n\n\nk = 1;\n\ny_hat = Beta0 + Beta1*x1;\nReg = y_hat-y_barra;\nSQReg = t(Reg)*Reg;\n\nRes = y-y_hat;\nSQRes = t(Res)*Res;\ns2 = SQRes/(n-k-1);\n* s2 = (t(y)*y - t(Beta)*t(X)*y)/(n-k-1);\nres_pad = res/sqrt(s2);\n\n*pág. 141;\nprint 'Valores observados(y) e estimados(y_hat), residuo(res) e residuo padronizado(res_pad):',\n      '--------------------------------------------------------------------------------------'; \nprint y '   ' y_hat [format=8.4] '   ' res [format=8.4]  '   ' res_pad [format=8.4],,,;\n\n\nvar_y = (t(y)*(In - (1/n)*Jnn)*y)/(n-1); * Calcula a variância amostral de y;\ns = sqrt(s2);\n\nprint 'Variância dos dados originais:' var_y [format=10.4],,\n      'Variância de y|x:             ' s2[format=10.4],,\n      'Desvio padrão de y|x :        ' s[format=10.4] ,,,;"
  },
  {
    "objectID": "exemplo3.1.html#teste-de-hipóteses-e-intervalo-de-confiança-para-beta_1",
    "href": "exemplo3.1.html#teste-de-hipóteses-e-intervalo-de-confiança-para-beta_1",
    "title": "\n5  Regressão Linear Simples\n",
    "section": "\n5.4 Teste de Hipóteses e Intervalo de Confiança para \\(\\beta_1\\)\n",
    "text": "5.4 Teste de Hipóteses e Intervalo de Confiança para \\(\\beta_1\\)\n\nRealizaremos um teste de hipótese para \\(H_0: \\beta_1 = 0\\), com a suposição que \\(y_i \\sim N(\\beta_0+ \\beta_1x_i, \\space \\sigma^2)\\) ou \\(\\epsilon_i \\sim N(0, \\sigma^2)\\).\nDas propriedades de \\(\\hat\\beta_1\\) e \\(s^2\\), temos:\n\\[\nt = \\frac{\\hat\\beta_1}{\\sqrt{\\frac{s^2}{\\sum^n_{i=1}(x_i-\\bar{x})^2}}} =  \\frac{\\hat\\beta_1}{\\text{Erro padrão}}\n\\]\n\n\nR\nSAS\n\n\n\n\nx_barra &lt;- t(jn) %*% (x1 / n)\nx_barra\n\n         [,1]\n[1,] 58.05556\n\nvar_Beta0 &lt;- s2 * ((1 / n) + (x_barra^2 / (t(x1) %*% (In - (1 / n) * Jnn) %*% x1)))\nvar_Beta0\n\n         [,1]\n[1,] 43.78905\n\nstderr_Beta0 &lt;- sqrt(var_Beta0)\nstderr_Beta0\n\n         [,1]\n[1,] 6.617329\n\nvar_Beta1 &lt;- s2 / (t(x1) %*% (In - (1 / n) * Jnn) %*% x1)\nvar_Beta1\n\n            [,1]\n[1,] 0.009828088\n\nstderr_Beta1 &lt;- sqrt(var_Beta1)\nstderr_Beta1\n\n           [,1]\n[1,] 0.09913671\n\n\nComo valores da estatística t, temos:\n\nt0 &lt;- Beta0 / stderr_Beta0\nt0\n\n         [,1]\n[1,] 1.621033\n\nt1 &lt;- Beta1 / stderr_Beta1\nt1\n\n         [,1]\n[1,] 8.802456\n\n\nPara construir os limites de intervalo de confiança:\n\\[\n\\hat\\beta \\pm t_{\\alpha/2, n-2} \\sqrt{\\frac{s^2}{\\sum^n_{i=1}(x_i-\\bar{x})^2}}\n\\]\nonde \\(t_{(\\alpha/2, n-2)}\\) é o percentil de ordem \\(100(1-\\alpha)\\%\\) da distribuição \\(t\\) com \\(n-2\\) graus de liberdade e \\(\\alpha\\) é o nível de significância do teste.\n\nttab &lt;- qt(0.975, n - 2) # quantil t com probabilidade 0.975 e gl = n-2\nttab\n\n[1] 2.119905\n\nliminf0 &lt;- Beta0 - ttab * stderr_Beta0\nliminf0\n\n          [,1]\n[1,] -3.301202\n\nlimsup0 &lt;- Beta0 + ttab * stderr_Beta0\nlimsup0\n\n         [,1]\n[1,] 24.75502\n\nliminf1 &lt;- Beta1 - ttab * stderr_Beta1\nliminf1\n\n          [,1]\n[1,] 0.6624861\n\nlimsup1 &lt;- Beta1 + ttab * stderr_Beta1\nlimsup1\n\n         [,1]\n[1,] 1.082807\n\n\nDado que o \\(t\\) calculado para \\(\\beta_1\\) é maior que o limite superior, temos evidências para rejeitar \\(H_0: \\beta_1 = 0\\), com nível de significância de 5%.\n\n\n\n\nParâmetro\nEstimado\nVariância\nErro Padrão\nt\nIC 95%\n\n\n\nBo\n10.7269\n43.7890\n6.6173\n1.6210\n[-3.301 , 24.755]\n\n\nB1\n0.8726\n0.0098\n0.0991\n8.8025\n[0.662 , 1.083]\n\n\n\n\n\n\n\n\nx_barra = t(jn)*x1/n;\nvar_Beta0 = s2*(1/n + x_barra**2/(t(x1)*(In-(1/n)*Jnn)*x1));\nstderr_Beta0 = sqrt(var_Beta0);\n\nvar_Beta1 = s2/(t(x1)*(In-(1/n)*Jnn)*x1);\nstderr_Beta1 = sqrt(var_Beta1);\n\n\nttab = tinv(0.975,n-2);\nliminf0 = Beta0-ttab*stderr_Beta0; limsup0 = Beta0+ttab*stderr_Beta0;\nliminf1 = Beta1-ttab*stderr_Beta1; limsup1 = Beta1+ttab*stderr_Beta1;\n*pág.146;\nprint Beta0[format=10.4] var_Beta0[format=10.4] stderr_Beta0[format=10.4]\n      '     I.C.(Beta0,95%) = ' liminf0[format=10.4] limsup0[format=10.4] ,,, \n      Beta1[format=10.4] var_Beta1[format=10.4] stderr_Beta1[format=10.4] \n      '     I.C.(Beta1,95%) = ' liminf1[format=10.4] limsup1[format=10.4] ,,,;"
  },
  {
    "objectID": "exemplo3.1.html#coeficiente-de-determinação-r2",
    "href": "exemplo3.1.html#coeficiente-de-determinação-r2",
    "title": "\n5  Regressão Linear Simples\n",
    "section": "\n5.5 Coeficiente de Determinação (\\(r^2\\))",
    "text": "5.5 Coeficiente de Determinação (\\(r^2\\))\nO coeficiente de determinação (\\(r^2\\)) indica a proporção da variação em \\(y\\) que é explicada pelo modelo ou que é devida à regressão em \\(x\\). É definido como:\n\\[r^2 = \\frac{SQReg}{SQTotal} = 1 - \\frac{SQRes}{SQTotal}\\]\nem que:\n\n\\(SQReg\\) é a soma de quadrados da regressão;\n\\(SQRes\\) é a soma de quadrados dos resíduos;\n\\(SQTotal\\) é a soma de quadrados total (\\(SQTotal = SQReg + SQRes\\)).\n\n\n\nR\nSAS\n\n\n\nPara calcular \\(SQReg\\):\n\ny_barra &lt;- (1 / n) * Jnn %*% y\ny_barra\n\n          [,1]\n [1,] 61.38889\n [2,] 61.38889\n [3,] 61.38889\n [4,] 61.38889\n [5,] 61.38889\n [6,] 61.38889\n [7,] 61.38889\n [8,] 61.38889\n [9,] 61.38889\n[10,] 61.38889\n[11,] 61.38889\n[12,] 61.38889\n[13,] 61.38889\n[14,] 61.38889\n[15,] 61.38889\n[16,] 61.38889\n[17,] 61.38889\n[18,] 61.38889\n\nReg &lt;- y_hat - y_barra\nReg\n\n             [,1]\n [1,]  33.1120882\n [2,]  16.5318039\n [3,] -50.6619797\n [4,] -50.6619797\n [5,]  17.4044505\n [6,]   5.1873989\n [7,]  27.0035624\n [8,]  -9.6475923\n [9,]  27.8762089\n[10,]  30.4941486\n[11,] -34.9543420\n[12,]  24.3856228\n[13,] -50.6619797\n[14,] -24.4825835\n[15,]   0.8241662\n[16,]  16.5318039\n[17,]  13.9138643\n[18,]   7.8053385\n\nSQReg &lt;- t(Reg) %*% Reg\nSQReg\n\n         [,1]\n[1,] 14873.05\n\n\nJá \\(SQTotal\\):\n\nTot &lt;- y - y_barra\nTot\n\n            [,1]\n [1,]  33.611111\n [2,]  18.611111\n [3,] -61.388889\n [4,] -61.388889\n [5,]  17.611111\n [6,]  15.611111\n [7,]  10.611111\n [8,]   4.611111\n [9,]  36.611111\n[10,]  28.611111\n[11,] -61.388889\n[12,]  33.611111\n[13,] -26.388889\n[14,] -11.388889\n[15,]  10.611111\n[16,]  -6.388889\n[17,]  13.611111\n[18,]   4.611111\n\nSQTotal &lt;- t(Tot) %*% Tot\nSQTotal\n\n         [,1]\n[1,] 17944.28\n\nSQTotal &lt;- SQReg + SQRes\nSQTotal\n\n         [,1]\n[1,] 17944.28\n\n\nAssim, o coeficiente de determinação é dado por:\n\nR2 &lt;- SQReg / SQTotal\nR2\n\n          [,1]\n[1,] 0.8288463\n\n\nO coeficiente de correlação (\\(r\\)) é dado pela raiz quadrada do coeficiente de determinação (\\(r^2\\)).\n\nr &lt;- sqrt(R2)\nr\n\n        [,1]\n[1,] 0.91041\n\n\n\n\n\n\nCoeficiente de determinação (R2)\nCoeficiente de correlação (r)\n\n\n0.8288\n0.9104\n\n\n\n\nA estatística t para testar \\(H_0: \\beta_1 = 0\\) também pode ser expressa em termos de \\(r\\):\n\\[\nt = \\frac{r \\space \\sqrt{n - 2}}{\\sqrt{1-r^2}}\n\\]\n\ntcalc1 &lt;- r * sqrt(n - 2) / (sqrt(1 - r^2))\ntcalc1\n\n         [,1]\n[1,] 8.802456\n\ntcalc2 &lt;- Beta1 / stderr_Beta1\ntcalc2\n\n         [,1]\n[1,] 8.802456\n\n\nCom a estatística t, calculamos o p-valor da seguinte maneira:\n\np_valor &lt;- 2 * (1 - pt(abs(tcalc1), n - 2))\np_valor\n\n             [,1]\n[1,] 1.570688e-07\n\n\nOnde a função pt() retorna a função de distribuição da estatística t.\nDado que o p-valor é menor que \\(\\alpha = 0,05\\), rejeitamos \\(H_0: \\beta_1 = 0\\).\nPor fim, podemos ter uma visão geral dos resultados da análise de regressão a partir do modelo criado com a função lm().\n\nmodelo &lt;- lm(y ~ x1)\n\nsummary(modelo)\n\n\nCall:\nlm(formula = y ~ x1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.4345  -8.8437   0.3528   9.6466  24.2731 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 10.72691    6.61733   1.621    0.125    \nx1           0.87265    0.09914   8.802 1.57e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.85 on 16 degrees of freedom\nMultiple R-squared:  0.8288,    Adjusted R-squared:  0.8181 \nF-statistic: 77.48 on 1 and 16 DF,  p-value: 1.571e-07\n\n\n\n\n\nR2 = SQReg/SQTotal;  * Coeficiente de determinação - R2';\n\ncorr = sqrt(R2);\n\nprint '     SQTotal  =     SQReg   +    SQRes',,\n       SQTotal[format=12.4] SQReg[format=12.4] SQRes[format=12.4],,,\n      'Coeficiente de determinação (R2): ' R2[format=10.4],,,\n      'Coeficiente de correlação (r):    ' corr[format=10.4],,,;\n\ntcalc1 = Beta1/stderr_Beta1; * Para testar H0: Beta1 = 0;\ntcalc2 = corr*sqrt(n-2)/(sqrt(1-corr**2));\np_valor = 2*(1-cdf('t',abs(tcalc1),n-2));\n\nprint 'H0: Beta1 = 0   ' tcalc1[format=10.4] tcalc2[format=10.4] p_valor[format=10.4];\n\nquit;"
  }
]